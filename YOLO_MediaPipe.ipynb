{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_cuda_pytorch():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA is available! Device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "check_cuda_pytorch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\mwj05/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-6-20 Python-3.8.19 torch-2.3.1+cu121 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# torch_ver Yolov5\n",
    "yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s',\n",
    "                            device='cuda:0' if torch.cuda.is_available() else 'cpu')  # 예측 모델\n",
    "yolo_model.classes = [0]  # 예측 클래스 (0 : 사람)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose : Face + Body\n"
     ]
    }
   ],
   "source": [
    "start_dot = 0      # mp.solutions.pose 시작 포인트 (0: 얼굴부터 발목까지, 11: 어깨부터 발목까지)\n",
    "n_CONFIDENCE = 0.3    # MediaPipe Min Detectin confidence check\n",
    "y_CONFIDENCE = 0.3    # Yolv5 Min Detectin confidence check\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "attention_dot = [n for n in range(start_dot, 29)]\n",
    "\n",
    "# 관절 라인 그리기\n",
    "\n",
    "\"\"\"얼굴 포함\"\"\"\n",
    "draw_line = [[11, 13], [13, 15], [15, 21], [15, 19], [15, 17], [17, 19], \\\n",
    "            [12, 14], [14, 16], [16, 22], [16, 20], [16, 18], [18, 20], \\\n",
    "            [23, 25], [25, 27], [24, 26], [26, 28], [11, 12], [11, 23], \\\n",
    "            [23, 24], [12, 24], [9, 10], [0, 5], [0, 2], [5, 8], [2, 7]]\n",
    "print('Pose : Face + Body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolov4 바운딩 box 안에서 media pipe 데이터 전처리 함수\n",
    "\n",
    "def get_skeleton(video_path, attention_dot, draw_line):\n",
    "    frame_length = 30 # LSTM 모델에 넣을 frame 수\n",
    "\n",
    "    xy_list_list, xy_list_list_flip = [], []\n",
    "    cv2.destroyAllWindows()\n",
    "    pose = mp_pose.Pose(static_image_mode = True, model_complexity = 1, \\\n",
    "                        enable_segmentation = False, min_detection_confidence = n_CONFIDENCE)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if cap.isOpened():\n",
    "\n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "\n",
    "            if ret == True:\n",
    "\n",
    "                \"\"\" Yolo 바운딩 박스 및 좌표 추출\"\"\"\n",
    "                img = cv2.resize(img, (640, 640))\n",
    "                res = yolo_model(img)\n",
    "                res_refine = res.pandas().xyxy[0].values\n",
    "                nms_human = len(res_refine)\n",
    "                if nms_human > 0:\n",
    "                    for bbox in res_refine:\n",
    "                        \"\"\"바운딩 박스 상하좌우 크기 조절\"\"\"\n",
    "                        xx1, yy1, xx2, yy2 = int(bbox[0])-10, int(bbox[1]), int(bbox[2])+10, int(bbox[3])\n",
    "                        if xx1 < 0:\n",
    "                            xx1 = 0\n",
    "                        elif xx2 > 639:\n",
    "                            xx2 = 639\n",
    "                        if yy1 < 0:\n",
    "                            yy1 = 0\n",
    "                        elif yy2 > 639:\n",
    "                            yy2 = 639\n",
    "\n",
    "                        start_point = (xx1, yy1)\n",
    "                        end_point = (xx2, yy2)\n",
    "\n",
    "                        \"\"\" Yolov5 바운딩 박스 좌표 안에서 mediapipe Pose 추출\"\"\"\n",
    "                        if bbox[4] > y_CONFIDENCE: # bbox[4] : confidence 데이터\n",
    "                            # img = cv2.rectangle(img, start_point, end_point, (0, 0, 255), 2) # 바운딩 박스 그리기 : 데이터 추출 확인용\n",
    "                            c_img = img[yy1:yy2, xx1:xx2] # 바운딩 박스 좌표\n",
    "                            results = pose.process(cv2.cvtColor(c_img, cv2.COLOR_BGR2RGB)) # Yolov5 바운딩 박스 좌표 안에서 'mp_pose' 좌표\n",
    "\n",
    "                            if not results.pose_landmarks: continue\n",
    "                            idx = 0\n",
    "                            draw_line_dic = {}\n",
    "                            xy_list, xy_list_flip = [], []\n",
    "                            # 33 반복문 진행 : 33개 중 18개의 dot\n",
    "                            for x_and_y in results.pose_landmarks.landmark:\n",
    "                                if idx in attention_dot:\n",
    "                                    xy_list.append(x_and_y.x)\n",
    "                                    xy_list.append(x_and_y.y)\n",
    "                                    xy_list_flip.append(1 - x_and_y.x)\n",
    "                                    xy_list_flip.append(x_and_y.y)\n",
    "\n",
    "                                    x, y = int(x_and_y.x*(xx2-xx1)), int(x_and_y.y*(yy2-yy1))\n",
    "                                    draw_line_dic[idx] = [x, y]\n",
    "                                idx += 1\n",
    "\n",
    "                            if len(xy_list) != len(attention_dot) * 2:\n",
    "                                print('Error : attention_dot 데이터 오류')\n",
    "\n",
    "                            xy_list_list.append(xy_list)\n",
    "                            xy_list_list_flip.append(xy_list_flip)\n",
    "\n",
    "                            \"\"\"mediapipe line 그리기 부분 : 데이터 추출(dot) 확인용\"\"\"\n",
    "                            # for line in draw_line:\n",
    "                            #     x1, y1 = draw_line_dic[line[0]][0], draw_line_dic[line[0]][1]\n",
    "                            #     x2, y2 = draw_line_dic[line[1]][0], draw_line_dic[line[1]][1]\n",
    "                            #     c_img = cv2.line(c_img, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
    "                            # # cv2.imshow('Landmark Image', img)\n",
    "                            # cv2_imshow(img)\n",
    "                            # cv2.waitKey(1)\n",
    "\n",
    "            elif ret == False: break\n",
    "\n",
    "\n",
    "        # 부족한 프레임 수 맞추기\n",
    "        if len(xy_list_list_flip) < 15:\n",
    "            return False, False\n",
    "        elif len(xy_list_list_flip) < frame_length:\n",
    "            f_ln = frame_length - len(xy_list_list_flip)\n",
    "            for _ in range(f_ln):\n",
    "                xy_list_list.append(xy_list_list[-1])\n",
    "                xy_list_list_flip.append(xy_list_list_flip[-1])\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    return xy_list_list, xy_list_list_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/mwj05/OneDrive/바탕 화면/clips'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = 'C:/Users/mwj05/OneDrive/바탕 화면/clips' # dataset 경로\n",
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "# 영상 데이터에서 mp pose landmark dot 데이터 추출 부분\n",
    "raw_data = []\n",
    "\n",
    "for fold in os.listdir(video_path):\n",
    "    for video_name in os.listdir(video_path + '/' + fold):\n",
    "        if int(video_name.split('_')[3][:2]) >= 30: # video name 참조\n",
    "            if video_name.split('_')[2] == 'normal': label = 0\n",
    "            else: label = 1\n",
    "            skel_data_n, skel_data_f = get_skeleton('{}/{}'.format(video_path + '/' + fold, video_name), attention_dot, draw_line)\n",
    "            if skel_data_n != False:\n",
    "\n",
    "                seq_list_n = skel_data_n[:30]\n",
    "                seq_list_f = skel_data_f[:30]\n",
    "                raw_data.append({'key':label, 'value':seq_list_n})\n",
    "                raw_data.append({'key':label, 'value':seq_list_f})\n",
    "random.shuffle(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 backup_data.json에 성공적으로 백업되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# json 파일로 저장\n",
    "import json\n",
    "\n",
    "# 파일 경로 설정\n",
    "backup_file = 'backup_data.json'\n",
    "\n",
    "# 데이터를 JSON 형식으로 파일에 저장\n",
    "with open(backup_file, 'w') as f:\n",
    "    json.dump(raw_data, f, indent=4)\n",
    "\n",
    "print(f\"데이터가 {backup_file}에 성공적으로 백업되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_lstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
